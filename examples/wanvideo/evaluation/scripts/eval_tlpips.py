#!/usr/bin/env python3
"""
eval_tlpips.py

è®¡ç®—Temporal LPIPS (tLPIPS) - æ—¶åºæ„ŸçŸ¥çš„æ„ŸçŸ¥ç›¸ä¼¼åº¦
è¡¡é‡ç›¸é‚»å¸§ä¹‹é—´çš„æ„ŸçŸ¥è·³è·ƒç¨‹åº¦
"""

import sys
import argparse
import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List
import lpips
from torchvision.transforms import functional as TF

# æ·»åŠ é¡¹ç›®è·¯å¾„
utils_dir = Path(__file__).resolve().parent.parent / "utils"
sys.path.append(str(utils_dir))
from video_utils import load_video_frames, parse_video_filename


class TLPIPSEvaluator:
    """Temporal LPIPSè¯„ä¼°å™¨"""
    
    def __init__(self, net: str = 'alex', device: str = 'cuda'):
        """
        åˆå§‹åŒ–LPIPSæ¨¡å‹
        
        Args:
            net: ç‰¹å¾æå–ç½‘ç»œ ('alex', 'vgg', 'squeeze')
            device: è®¡ç®—è®¾å¤‡
        """
        print(f"æ­£åœ¨åŠ è½½LPIPSæ¨¡å‹ (ç½‘ç»œ: {net})...")
        self.device = torch.device(device)
        
        # spatial=False è¡¨ç¤ºè¾“å‡ºå•ä¸€çš„å…¨å±€è·ç¦»å¾—åˆ†
        self.lpips_model = lpips.LPIPS(net=net, spatial=False).to(self.device)
        self.lpips_model.eval()
        
        print("âœ“ LPIPSæ¨¡å‹åŠ è½½å®Œæˆ")
    
    @torch.no_grad()
    def calculate_video_tlpips(self, video_path: Path) -> float:
        """
        è®¡ç®—å•ä¸ªè§†é¢‘çš„å¹³å‡tLPIPS
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            float: å¹³å‡tLPIPSå€¼
        """
        try:
            # åŠ è½½è§†é¢‘å¸§ (T, C, H, W)
            frames = load_video_frames(video_path)
            
            if frames.shape[0] < 2:
                return 0.0  # å•å¸§è§†é¢‘
            
            tlpips_scores = []
            
            # è®¡ç®—ç›¸é‚»å¸§çš„LPIPS
            for t in range(frames.shape[0] - 1):
                frame_t = frames[t].unsqueeze(0).to(self.device)  # (1, C, H, W)
                frame_t_plus_1 = frames[t + 1].unsqueeze(0).to(self.device)
                
                # LPIPSè¦æ±‚è¾“å…¥åœ¨[-1, 1]èŒƒå›´
                frame_t_norm = (frame_t * 2.0) - 1.0
                frame_t_plus_1_norm = (frame_t_plus_1 * 2.0) - 1.0
                
                # è®¡ç®—LPIPSè·ç¦»
                score = self.lpips_model(frame_t_norm, frame_t_plus_1_norm)
                tlpips_scores.append(score.item())
            
            return np.mean(tlpips_scores)
        
        except Exception as e:
            print(f"\nè­¦å‘Š: å¤„ç† {video_path.name} å¤±è´¥: {e}")
            return np.nan
    
    def evaluate_directory(
        self,
        video_dir: Path,
        output_file: Path = None
    ) -> Dict[str, Dict[str, float]]:
        """
        è¯„ä¼°ç›®å½•ä¸­æ‰€æœ‰è§†é¢‘çš„tLPIPS
        
        Args:
            video_dir: è§†é¢‘ç›®å½•
            output_file: ç»“æœä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict: æŒ‰çº§åˆ«ç»„ç»‡çš„ç»“æœ
                {
                    "level_0": {"mean": 0.123, "std": 0.045, "videos": 33},
                    ...
                }
        """
        video_files = sorted(video_dir.glob("video_*.mp4"))
        
        if not video_files:
            print(f"é”™è¯¯: åœ¨ {video_dir} ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return {}
        
        print(f"\næ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        print("å¼€å§‹è®¡ç®—tLPIPS...\n")
        
        # æŒ‰çº§åˆ«åˆ†ç»„ç»“æœ
        results_by_level = {
            "level_0": [],
            "level_1": [],
            "level_2": [],
            "level_3": []
        }
        
        # è®¡ç®—æ¯ä¸ªè§†é¢‘çš„tLPIPS
        for video_path in tqdm(video_files, desc="è®¡ç®—tLPIPS"):
            level, prompt_id, seed = parse_video_filename(video_path.name)
            
            tlpips_value = self.calculate_video_tlpips(video_path)
            
            if not np.isnan(tlpips_value):
                results_by_level[f"level_{level}"].append(tlpips_value)
        
        # æ±‡æ€»ç»Ÿè®¡
        summary = {}
        for level, scores in results_by_level.items():
            if scores:
                summary[level] = {
                    "mean": float(np.mean(scores)),
                    "std": float(np.std(scores)),
                    "median": float(np.median(scores)),
                    "min": float(np.min(scores)),
                    "max": float(np.max(scores)),
                    "videos": len(scores)
                }
            else:
                summary[level] = {
                    "mean": np.nan,
                    "std": np.nan,
                    "median": np.nan,
                    "min": np.nan,
                    "max": np.nan,
                    "videos": 0
                }
        
        # æ‰“å°ç»“æœ
        self._print_results(summary)
        
        # ä¿å­˜ç»“æœ
        if output_file:
            self._save_results(summary, output_file)
        
        return summary
    
    def _print_results(self, summary: Dict):
        """æ‰“å°æ ¼å¼åŒ–çš„ç»“æœ"""
        print("\n" + "="*80)
        print("Temporal LPIPS (tLPIPS) è¯„ä¼°ç»“æœ")
        print("="*80)
        print(f"{'çº§åˆ«':<25} {'å‡å€¼':<12} {'æ ‡å‡†å·®':<12} {'ä¸­ä½æ•°':<12} {'è§†é¢‘æ•°'}")
        print("-"*80)
        
        for level in ["level_0", "level_1", "level_2", "level_3"]:
            stats = summary[level]
            level_name = {
                "level_0": "Level 0 (Abs. Baseline)",
                "level_1": "Level 1 (Style Baseline)",
                "level_2": "Level 2 (Joint Style)",
                "level_3": "Level 3 (Fully Enhanced)"
            }[level]
            
            if stats["videos"] > 0:
                print(f"{level_name:<25} {stats['mean']:<12.6f} {stats['std']:<12.6f} "
                      f"{stats['median']:<12.6f} {stats['videos']}")
            else:
                print(f"{level_name:<25} {'N/A':<12} {'N/A':<12} {'N/A':<12} {stats['videos']}")
        
        print("="*80)
        print("\nğŸ’¡ è§£è¯»: tLPIPSè¶Šä½è¶Šå¥½ï¼Œè¡¨ç¤ºå¸§é—´æ„ŸçŸ¥è·³è·ƒè¶Šå°")
        print("   é¢„æœŸ: Level 3 < Level 2 < Level 1 â‰ˆ Level 0")
        print("="*80 + "\n")
    
    def _save_results(self, summary: Dict, output_file: Path):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        import json
        
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


def main():
    parser = argparse.ArgumentParser(description="è®¡ç®—è§†é¢‘çš„Temporal LPIPS")
    parser.add_argument(
        "--video_dir",
        type=str,
        required=True,
        help="åŒ…å«æ‰€æœ‰è¯„ä¼°è§†é¢‘çš„ç›®å½•"
    )
    parser.add_argument(
        "--output_file",
        type=str,
        default="./evaluation_outputs/metrics/tlpips_results.json",
        help="ç»“æœä¿å­˜è·¯å¾„"
    )
    parser.add_argument(
        "--net",
        type=str,
        choices=['alex', 'vgg', 'squeeze'],
        default='alex',
        help="LPIPSç‰¹å¾æå–ç½‘ç»œ"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="è®¡ç®—è®¾å¤‡"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = TLPIPSEvaluator(net=args.net, device=args.device)
    
    # æ‰§è¡Œè¯„ä¼°
    evaluator.evaluate_directory(
        video_dir=Path(args.video_dir),
        output_file=Path(args.output_file)
    )


if __name__ == "__main__":
    main()